%*****************************************
\chapter{Results}\label{ch:results}
%*****************************************


\section{Reflective Knowledge Substrate}


\subsection{General Parallelism and Concurrency}

My system is built to handle concurrent parallel processes on
multi-core operating systems.  In this section, I test how efficient
my implementation of concurrency performs on a number of standard
concurrency timing tasks.  In an ideal situation, given $N$ processor
core working on independenct problems, I should get a factor of $N$
speedup.  Because multiple core processors share memory resources this
ideal is never actualized, so we test our implementations performance
by developing appropriate metrics.

\subsection{Program as Data}

In systems where the program is data, a bottleneck in writing programs
that write programs is the efficiency of the run-time compiler.  In
this section we test the relative performance of our compiler in
our-time system.

\section{Layered Reflective Problem Solving}

In this section, I evaluate how well different configurations of my
learning system accomplishes a range of goals in the blocks world
environment.

\subsection{Comparison between Learned Reactions and Planning}

I evaluate how adding or removing reflectively learning to plan
changes the performance of the blocks world goal accomplishment
metric.

\subsection{Analogy between Physical Goals and Planning Goals}

I evaluate how adding or removing the second layer of reflectively
learning to plan changes the performance of the blocks world goal
accomplishment metric.

\section{Learning by Credit Assignment}

\subsection{Tracing Knowledge Provenance for Credit Assignment of Success or Failure}

I evaluate how tracing causality of knowledge provenance can improve
learning performance according to the blocks world goal accomplishment
metric.

