\chapter{Causal Reflective Tracing Tutorial}
\label{appendix:causal_reflective_tracing_tutorial}

Large concurrent and parallel systems are difficult to build and debug
because of the complex causal interactions between all of the
different processes.  For this reason, every process fiber in Funk has
an associated \emph{cause} object.  If any process fiber creates a new
process fiber, then a new cause object is created for the child
process thread with a parent cause object reference.  Cause objects
represent the properties of a process, which can be used for causally
organizing parallel tasks, controlling and monitoring the occurrence
of any type of event through any of the procedural abstraction
barriers of the Funk virtual machine.

\section{Funk Virtual Operating System}

Parallel tasks in the Funk virtual operating system are called
\emph{fibers} in order to distinguish them from the \emph{threads} in
the underlying non-virtual operating system.  The parallel fibers
create, mutate, and read from memory as they execute sequences of
bytecodes.  At any point between bytecode executions, the Funk memory
system is static.  The current execution state of every fiber is
represented in the global environment.  In order for Funk to be fully
reflective on all of the procedural effects of any given fiber, I
introduce a technique that I call \emph{causal reflective tracing}.
Causal reflective tracing is a way of defining variables that are
specific to each fiber that can be used to control the low-level
memory access, mutation, and creation functions.  This allows one
fiber within Funk to subscribe to the procedural trace events of
another fiber without receiving procedural trace events of its own
execution, which would lead to an infinite regress, halting the
system.  Further, because Funk is inherently a parallel processing
system, a given fiber will often start a number of child fibers that
handle part of the processing for the parent fiber.  When a new fiber
is created, the child fiber inherits the causal variable bindings of
its parent fiber, enabling the same procedural tracing options for the
child as well.  So, causal reflective tracing is one of the basic
tools for keeping track of which pieces of memory were created,
mutated, or read by which other fibers.  When evaluating the
theoretical time complexity of concurrent procedurally reflective
control algorithms, it should be noted that creating procedural trace
events for the execution of a given fiber slows the fiber down only by
a constant factor, not affecting the algorithm's ``big-O'' time
complexity on an ideal concurrent shared-memory system, of which the
Funk virtual operating system is an approximation.

\section{Semantic Memory Focuses Reflective Tracing}

While causal reflective tracing focuses the procedural event tracing
to memory interactions of specific fibers, this still results in
millions of events to consider every real-time second of execution.
In order to further focus on specific objects within the Funk memory
system, specific pieces of memory can be created called
``\emph{semantic memory}''.  Semantic memory objects are created,
mutated, and accessed in roughly the same way as all of the
frame-based objects in the Funk memory system with a few extra
reflective tracing features.  For example, semantic objects provide
event streams that can be subscribed to by a number of different
parallel listeners in different fibers.

Because it becomes awkward to subscribe to each an every frame-based
object that may be interesting to the reflective focus, semantic
frames that are created by specific fibers can be added to collections
of semantic frames that are called \emph{semantic knowledge-bases}.
Semantic knowledge-bases are good for organizing entire layers or
subsets of reflective layers that contain different types of semantic
frames.  Semantic knowledge-bases allow the same forgetful event
stream subscription services as semantic frames with the additional
capability of tracing the addition and removal of entire semantic
frames to and from the knowledge-base.

While knowledge-base reconstructions are extremely fast to reference,
$O(1)$, they require a duplication of the memory requirements of the
focus knowledge base for every different point in time that is
required.  In order to allow efficient access of the state of
knowledge-bases at arbitrary points in the past, \emph{semantic event
  interval-tree knowledge-bases} are another type of representation
that is reflectively maintained without slowing down the procedure
under reflective focus.  A semantic event knowledge-base stores a type
of semantic frame that represents when a given semantic frame has a
specific slot value called a \emph{semantic event}.  A semantic event
is a semantic frame is an interval that spans a time from a beginning
time and an ending time, each of which may or may not be specified.
Semantic event knowledge-bases are reflectively traced and the
knowledge is always stored in two different representations, the basic
semantic event frames as well as a balanced interval tree that always
represents the current state of the semantic event knowledge-base.
The balanced interval tree allows accessing the state of the focus
knowledge-base in $O(log n)$ time, where $n$ is the number of events
stored in the semantic event knowledge base.  Although the time
complexity is not as efficient as the constant, $O(1)$, access time of
the reflectively reconstructed semantic knowledge-base, the semantic
event interval-tree knowledge base only requires $O(n)$ memory
complexity in order to allow access to the structure of the
knowledge-base at any point in the past, where $n$ is the number of
semantic events.
{\mbox{\autoref{figure:semantic_event_knowledge_base}}} shows how to
create a new ``{\tt{semantic\_event\_knowledge\_base}}'' type object.
\begin{figure}[h]
\centering
{\small
\begin{Verbatim}[frame=single]
 in-> [new semantic_event_knowledge_base nil [new semantic_realm]]
out-> [semantic_event_knowledge_base
        semantic_event_tree         [semantic_event_tree ...]
        semantic_frame_set          [set ...]
        trace_remove_semantic_frame []
        trace_callback_funks_frame  [frame ...]
        semantic_realm              [semantic_realm ...]
        trace_event_stream          [forgetful_event_stream ...]
        trace_add_semantic_frame    []
        ...]
\end{Verbatim}
}
\caption[How to create a new
  ``{\tt{semantic\_event\_knowledge\_base}}'' type object.]{How to
  create a new ``{\tt{semantic\_event\_knowledge\_base}}'' type
  object.  When ``{\tt{semantic\_event}}'' type objects are added,
  removed, or modified while they are in this type of knowledge base,
  the knowledge base updates an always-accurate event interval tree
  structure for all of the events for efficient, $O(\log n)$, access
  to the events at any point in time.}
\label{figure:semantic_event_knowledge_base}
\end{figure}

\section{Forgetful Event Streams}

By default, when there are no listeners to the procedural event
streams of a semantic frame-based object, no reflective events are
created, allowing the use of the object to run at full speed.  When a
listener subscribes to the procedural use of a specific semantic
memory object, events are added to ordered streams for the listening
subscribers.  In order to conserve memory resources, when multiple
parallel listeners are subscribed to a given event stream, only those
events that have not already been seen by all of the subscribers are
remembered.  Once all subscribers have processed an event, all events
before this event are forgotten.  This type of memory conserving event
stream is referred to as a \emph{forgetful event stream}.  In this way
semantic frames report the addition and removal of slot values to
reflective forgetful event stream subscribers.  Once a knowledge base
is created and we have an important event stream iterator, we can
define a concurrent reflective fiber that processes the events
reflectively, after the real-time execution of the processes that
modify this knowledge base.
{\mbox{\autoref{figure:reflective_fiber}}} shows an example of how a
reflective fiber can be created to process an
{\tt{forgetful\_event\_stream}} generated by a
{\tt{semantic\_knowledge\_base}}, which includes a traced
{\tt{semantic\_planner}}.
\begin{figure}[h]
\centering
{\small
\begin{Verbatim}[frame=single]
 in-> [let* [[realm          [new semantic_realm]]
             [knowledge_base [new semantic_event_knowledge_base
                                  nil realm]]
             [iterator       [get knowledge_base
                                  new-event_stream_iterator]]
             [planner        [new semantic_planner realm]]]

        'Start parallel reflective fiber.'
        [fiber [funk []
                 [while t
                   [let [[event [have iterator wait_for_current]]]
                     [print event]
                     [have iterator increment]]]]
               []]
        
        [set planner trace_add    t]
        [set planner trace_remove t]
        
        [have knowledge_base add_semantic_frame planner]
        
        [set planner imagine_time [new semantic_time [time]]]]
out-> []
\end{Verbatim}
}
\caption[A reflective fiber can be created to process an
  {\tt{forgetful\_event\_stream}}.]{A reflective fiber can be created
  to process a {\tt{forgetful\_event\_stream}} generated by a
  {\tt{semantic\_knowledge\_base}}, which includes a traced
  {\tt{semantic\_planner}}.  Note that this example runs at a constant
  factor slower than full speed because of the creation of mutation
  events for the {\tt{semantic\_planner}} object, but this factor has
  been kept relatively small, so this example completes almost
  immediately.  The reflective process runs slower because it must
  consider how to print these events to the terminal in a readable
  form.  {\mbox{\autoref{figure:remove_add_set_events}}} shows the
  last two events created by the last line of this example that
  mutates the {\tt{imagine\_time}} slot value for the planner.}
\label{figure:reflective_fiber}
\end{figure}

\begin{figure}[h]
\centering
{\small
\begin{Verbatim}[frame=single]
[semantic_frame_event
  time           [time
                   years        2012
                   months       8
                   days         31
                   ...]
  event_type     remove
  semantic_frame [semantic_planner
                   property phenomenal_name [...]
                   property planner_type    [[]]
                   property imagine_time    [[semantic_time ...]]
                   relation execute_plan    [[]]
                   relation imagine_plan    [[]]
                   relation focus_plan      [[]]
                   ...]
  key_type       property
  key            imagine_time
  value          []]
\end{Verbatim}
\begin{Verbatim}[frame=single]
[semantic_frame_event
  time           [time years 2012 months 8 days 31 hours 23 ...]
  event_type     add
  semantic_frame [semantic_planner
                   property phenomenal_name [...]
                   property planner_type    [...]
                   property imagine_time    [...]
                   relation execute_plan    [...]
                   ...]
  key_type       property
  key            imagine_time
  value          [semantic_time
                   value [time
                           years        2012
                           months       8
                           days         31
                           ...]]]
\end{Verbatim}
}
\caption[The last two events created by the last line of the example
  in {\mbox{\autoref{figure:reflective_fiber}}}.]{The last two events
  created by the last line of the example in
  {\mbox{\autoref{figure:reflective_fiber}}}:
  ``{\tt{[set~planner~imagine\_time~[new~semantic\_time~[time]]]}}''. This
  command mutates the {\tt{imagine\_time}} slot value for the planner.
  Notice that the first of the two events is a {\tt{remove}} type of
  event, while the second is an {\tt{add}} type event.  This event
  knowledge is used in the AI to create reconstructions of entire
  knowledge bases of physical as well as deliberative object types,
  like planners.  Note that the first event removes the {\tt{[]}} slot
  value of the {\tt{imagine\_time}} {\tt{property}} of the
  {\tt{semantic\_planner}} object, while the second event adds the new
  value, thus completing the mutation.}
\label{figure:remove_add_set_events}
\end{figure}

\section{Causal Tracing of Statistics}

Every parallel fiber in Funk is part of a causal scope of execution.
Every fiber is created with a unique {\tt{cause}} object that provides
a consolidation of reflective tracing features for the fiber.  While a
fiber's cause may be changed so that multiple fibers share the same
cause object, a convenient solution to organizing very dynamic causal
reflection is provided by the {\tt{cause\_group}} object.  Cause
groups are added to cause objects and inherited from parent to child
when new causes are created.  Because {\tt{cause}} objects and
{\tt{cause\_group}} objects exist at the locus of every single memory
creation or mutation event in the entire Funk operating system, they
are a valuable and necessarily efficient means of tracing any event
that modifies any part of the operating system.  For example,
{\mbox{\autoref{figure:cause_group_statistics}}} the simplest type of
causal reflective tracing simply gathers run-time statistics of a
fiber execution by using a {\tt{cause\_group}} object.
{\mbox{\autoref{figure:hierarchical_cause_group_statistics}}} shows an
example of using a hierarchy of causal scopes in order to trace a
total of $30$ parallel fibers that are organized into $3$ groups of
$10$.
\begin{figure}[h]
\centering
{\small
\begin{Verbatim}[frame=single]
 in-> [globalize cause_group [new cause_group]]
out-> []

 in-> [with-new-cause
        [have [this-cause] add_cause_group cause_group]
        [partimes [i 10]
          [print i]]]
0
1
2
3
4
6
7

58
9
out-> []

 in-> cause_group
out-> [cause_group
        execution_nanoseconds 533248657
        bytes_allocated_count 2766181
        bytecode_count        19495
        bytes_freed_count     0]
\end{Verbatim}
}
\caption[Using a {\tt{cause\_group}} object to gather statistics from
  causally scoped executions.]{Using a {\tt{cause\_group}} object to
  gather statistics from causally scoped executions.  First, a new
  {\tt{cause\_group}} object is created in the global environment.
  Then, the gathering of run-time statistics involves creating a new
  cause with the ``{\tt{with-new-cause}}'' operator, adding this cause
  to the {\tt{cause\_group}} object, and then running an experiment.
  The experiment in this case creates ten parallel fibers that each
  simply print their index, a number from $0$ to $9$.  Finally, the
  global {\tt{cause\_group}} object is printed to the screen, showing
  processor execution time, total bytes allocated, total bytecodes
  executed, and also the number of bytes garbage collected during the
  experiment.  Note that multiple experiments could be run in parallel
  and have separately scoped cause groups and statistics.}
\label{figure:cause_group_statistics}
\end{figure}
\begin{figure}[h]
\centering
{\small
\begin{Verbatim}[frame=single]
 in-> [globalize cause_group [new cause_group]]
out-> []

 in-> [let [[begin_time [time]]
            [frame      [new frame]]]
        [with-new-cause
          [have [this-cause] add_cause_group cause_group]
          [partimes [i 3]
            [let [[subcause_group [new cause_group]]]
              [have frame add i subcause_group]
              [with-new-cause
                [have [this-cause] add_cause_group subcause_group]
                [partimes [j 10]
                  [terminal_format standard-terminal j]]]]]]
        [have frame add `real-time [- [time] begin_time]]
        frame]
024031548162062794915695337878                      
out-> [frame
        0         [cause_group
                    execution_nanoseconds 3535418608
                    bytes_allocated_count 7715763
                    ...]
        2         [cause_group
                    execution_nanoseconds 3012761500
                    bytes_allocated_count 7590735
                    ...]
        1         [cause_group
                    execution_nanoseconds 3976116760
                    bytes_allocated_count 9598095
                    ...]
        real-time [relative_time
                    seconds      1
                    milliseconds 694
                    ...]]

 in-> cause_group
out-> [cause_group
        execution_nanoseconds 10730429054
        bytes_allocated_count 25622218
        bytecode_count        215649
        bytes_freed_count     0]
\end{Verbatim}
}
\caption[Gathering run-time statistics using parallel hierarchies of
  causal scopes.]{Gathering run-time statistics using parallel
  hierarchies of causal scopes.  Overall, $30$ parallel fibers are
  created, each prints a number from $0$ to $9$, and run-time
  statistics are gathered in two layers of causal scope hierarchy.
  The overall {\tt{cause\_group}} object is shown last, while three
  sub-{\tt{cause\_group}} objects are printed as the return value of
  the second expression.  Notice that the algorithm uses $10.7$
  seconds of processor time, while only using $1.7$ seconds of
  real-time.}
\label{figure:hierarchical_cause_group_statistics}
\end{figure}

\section{Causal Tracing of Memory Creation}

Sometimes it is helpful to know which fiber or cause created a
specific piece of memory.  For this reason, every piece of memory in
the entire Funk operating system includes a reference to its creation
cause as well as its creation fiber.  This increases memory usage by a
constant factor, not making any algorithms in the operating system
require any greater time or memory complexity, but for small objects
it does triple the memory requirements.  This information can be
useful in many statistical ways, such as keeping track of memory
interactions between {\tt{cause\_group}} objects.  The focus of this
thesis is not, however, a statistical point.
{\mbox{\autoref{figure:reflective_event_causal_tracing}}} shows how a
reflective fiber can retrieve the creation cause of a procedurally
generated event, a reflective tracing experiment where the creation
cause of the reflective event is a useful piece of information to know
for non-statistical reasons, such as learning from the separate
effects of different causal scopes on a given knowledge base.  Causal
tracing in the AI is used to detect when one resource interacts with
another resource, for example, by activating that resource or waiting
for that resource to complete execution.  An entire reflective
knowledge base of current parallel resource interactions is maintained
in this way.
\begin{figure}[h]
\centering
{\small
\begin{Verbatim}[frame=single]
 in-> [let* [[realm          [new semantic_realm]]
             [knowledge_base [new semantic_event_knowledge_base
                                  nil realm]]
             [iterator       [get knowledge_base
                                  new-event_stream_iterator]]
             [planner        [new semantic_planner realm]]]

        'Start parallel reflective fiber.'
        [fiber [funk []
                 [while t
                   [let* [[event       [have iterator
                                             wait_for_current]]
                          [event-cause [get event cause]]]
                     [if [eq `my-test [have event-cause lookup
                                            `cause-name]]
                         [print `event-in-causal-focus]
                       [print `event-out-of-causal-focus]]
                     [have iterator increment]]]]
               []]
        
        [set planner trace_add    t]
        [set planner trace_remove t]
        
        [have knowledge_base add_semantic_frame planner]
        
        [with-new-cause
          [cause-define cause-name `my-test]
          [set planner imagine_time [new semantic_time [time]]]]]
out-> []
event-out-of-causal-focus
event-out-of-causal-focus
event-out-of-causal-focus
event-out-of-causal-focus
event-out-of-causal-focus
event-out-of-causal-focus
event-out-of-causal-focus
event-out-of-causal-focus
event-in-causal-focus
event-in-causal-focus
\end{Verbatim}
}
\caption[Causally scoped reflective event tracing.]{Causally scoped
  reflective event tracing.  Since every piece of memory in the Funk
  virtual operating system has a reference to its {\tt{cause}} object,
  causally focusing the reflective tracing example shown in
  {\mbox{\autoref{figure:reflective_fiber}}} is simply a matter of
  accessing the creation cause of each event, using the expression,
  {\tt{[get event cause]}}.}
\label{figure:reflective_event_causal_tracing}
\end{figure}

\section{Inter-fiber Communication Through Trigger Events}

Creating a parallel fiber can be an efficient way to execute
functionality that must occur at some uncertain future point in time.

\section{Conjunctive Hypothesis Space Concept Learning}

I have implemented a learning algorithm that is inspired by
\citeauthor{mitchell:1997}'s \citeyear{mitchell:1997} version-space
hypothesis space concept learning algorithm.  My implementation
predicts a binary output feature given a frame of slots and symbolic
slot values as input features with a relatively compact representation
of the entire conjunctive hypothesis space by only representing the
most general and most specific boundaries in the overall hypothesis
generality lattice, thus the entire space is represented without
redundancy of hypotheses that predict the same things as other
hypotheses, given the training data seen so far.  The algorithm is
incremental, meaning that it learns incrementally in real-time by
being given new examples whenever they become available.  Also, I've
implemented hooks into the concept version space learning algorithm,
so that the most specific hypotheses or most general hypotheses that
support a positive or negative outcome, respectively, can be easily
retrieved from the version space, and each of these hypotheses have
``removal callbacks'' that will be called if this hypothesis is ever
removed from the version space.  These hooks allow the implementation
of the dependency tracing learning algorithm for correcting
hypothetically supported counterfactual knowledge by having these
callbacks invalidate dependency objects that are the supports for all
counterfactual knowledge.
{\mbox{\autoref{figure:concept_version_space}}} shows how to create a
{\tt{concept\_version\_space}} object that can be trained.
{\mbox{\autoref{figure:concept_version_space_training}}} shows an
example of training the {\tt{concept\_version\_space}} object, given
training examples.
\begin{figure}[h]
\centering
{\small
\begin{Verbatim}[frame=single]
 in-> [new concept_version_space]

out-> [concept_version_space
        specific_hypotheses [[concept_version_space_hypothesis]]
        general_hypotheses  [[concept_version_space_hypothesis]]
        variable_name_set   [set elements []]]
\end{Verbatim}
}
\caption[Creating a new {\tt{concept\_version\_space}} conjunctive
  hypothesis learning algorithm.]{Creating a new
  {\tt{concept\_version\_space}} conjunctive hypothesis learning
  algorithm.  Notice that this object keeps a list of specific
  hypotheses that support positive output predictions as well as
  general hypotheses that support negative output predictions.  Also,
  there is a set of variable names, or frame slot names, that the
  algorithm has seen previously.}
\label{figure:concept_version_space}
\end{figure}
\begin{figure}[h]
\centering
{\small
\begin{Verbatim}[frame=single]
 in-> [let [[concept [new concept_version_space]]]

        'Add a training example to the concept.'
        [let [[example [new concept_version_space_example t]]]
          [have example add_variable_value `color `blue]
          [have example add_variable_value `shape `cube]
          [have concept train_on_example example]]
        
        'Add a training example to the concept.'
        [let [[example [new concept_version_space_example nil]]]
          [have example add_variable_value `color `blue]
          [have example add_variable_value `shape `cube]
          [have concept train_on_example example]]
        
        concept]
        
\end{Verbatim}
}
\caption[Training a {\tt{concept\_version\_space}} conjunctive
  hypothesis learning algorithm.]{Training a
  {\tt{concept\_version\_space}} conjunctive hypothesis learning
  algorithm.}
\label{figure:concept_version_space_training}
\end{figure}

