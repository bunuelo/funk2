%************************************************
\chapter{Cause and Effect}
\label{chapter:cause_and_effect}
%************************************************

\section{Resources}

Activities in Duration can be referred to symbolically by the
reflective thinking layers.  While all activities in all layers are
generally willful qualities of Duration, these activities can be
symbolized as potentially actionable parts of plans by the reflective
thinking layers.  I will refer to a symbolic reference to activities
that can be put into plans as a \emph{resource}.  Resources exist in
the thinking layers as symbolic references to activities in the layers
below.

\section{Activation and Suppression}

In my model, I've included a logical idea that I refer to as
\emph{suppression}.  Suppression is a symbolic relationship to a
resource that can be put into plans.  The idea of suppression is a
subtle point with respect to the qualities of Duration.  The basic
problem is that the qualities of Duration are the willful activities
that exist without thinking necessarily existing.  Further, the
activities in Duration cannot be inactive, by definition; a symbolic
reference to something inactive would imply a symbol that refers to
something that does not exist, a contradiction.  Therefore, the
logical idea of suppression is an artificial tool of thought, part of
the thinking layers, separate from the physical activities entirely.
The subtle point here is that suppression does not disable the
potential for willful activities.  In my model, suppression is a
logical block for a thinking activity that I will refer to as
\emph{activation}.  Activation and suppression refer to types of
Spatial relationships that are maintained between symbolic resources.
Therefore, it would not be correct to say that physical activities
have been activated or suppressed, but alternatively, it would be
correct to say that a resource is in a Spatial relationship that has
activated or suppressed qualities.  The activation and suppression of
resources occurs in the sense of actively creating Spatial qualities.

Therefore, in my model, a resource can be both either activated or
suppressed, which does not, by itself, imply a resultant activity in
the layer below; logically, if a resource is activated and is not
otherwise suppressed, then the resource is considered logically to be
activated; however, when a resource is both activated and suppressed
simultaneously, this is a logical failure that is cause for a plan to
halt execution.  Before discussing potential responses to plans
failing in this way, let me first discuss the basics of the planning
process.

\section{Cause and Effect}

Two symbols correlated in time are not enough to compose a causal
relationship.  Two symbols correlated in time are simply a transition
from the past to the future.  A causal relationship supposes an
additional component, a necessary connective symbolic reference to the
activities that are ongoing during the transition.  Thus, the effect
of the causal component is the transition.  A causal relationship,
therefore, has three parts: the symbolized qualities of Duration
active in the present, the symbolized qualities of Duration in the
past, and the symbolized qualities of Duration in the future.  I will
sometimes refer to these three parts of the causal relationship more
succinctly as (1) the cause, (2) the necessity, and (3) the result.
When causal models are used for planning, the symbolic reference that
is the cause is referred to as a resource.

\section{Goal and Failure Activities}

It is important to understand that, in my model, goals and failures
are not derivatives of symbolized perceptions.  Fundamentally,
symbolized goals and failures refer to the activities in Duration that
give direction to the activities of thinking.  Goals and failures can
thus be arranged in Spatial orders, according to preferential
qualities.

Bergson refers to activities in Duration as generally \emph{willful}.
In my model, a goal is simply a reference to these activities that
symbolically either exist or do not exist in Duration.  Qualities of
Duration can be willfully reflectively symbolized as goals or
failures.  A symbolized goal is a reference to activities that are to
be sought, while a symbolized failure is a reference to activities
that are to be avoided.

The first-order reflective layer willfully symbolizes goals and
failures and this creation of a symbolic reference to goal or failure
activities becomes the reason for planning and acting toward or away
from the associated perceptions.  Note that because symbolic goals,
failures, perceptions, and resources in my model are artificial and do
not derive from one another, a process of refining symbolic references
to perceptions and resources can be undertaken in the pursuit of
creating more accurate causal models that predict the activities in
Duration that symbolic goals and failures reference.

\section{Causal Hypothesis}

When goal or failure activities are symbolized, causal hypotheses are
created for predicting the goal or failure activities in the future.
For example, if there are ongoing activities happening simultaneously
with the symbolization of the goal or failure, these can be
hypothesized as causes of the future symbolized goal or failure.
Remember that a causal model has three parts: present cause, past, and
future.  In this case, the goal or failure is placed in a future
context, the symbolized current activity is in the present, and there
must also be a past symbol to fill the last slot in the model.

\section{Limitations of Logical Goals and Failures}

Logical approaches to AI have seen the value in considering goals and
failures to be relative arrangements of perceptual symbols.  These
sorts of symbolic relationships in my model are thought of as
occurring simultaneously with, before or after goal or failure
activities.  Artificial constructions that are actively maintained in
Spatial arrangement can be reified as symbolic perceptions, but
fundamentally the goal or failure does not refer to an artificial
construction, despite the possible correlation of goals and failures
with such constructions.  In this way, my model gains the ability to
think about and refine symbolization itself with respect to goals that
are not fundamentally in terms of artificial constructions.
Artificial constructions are useful tools for accomplishing goal
activities; however, reflectively, all artificial constructions,
including symbols, are caused by the AI itself and the responsible
activities can change.  In other words, in purely logical approaches
to AI, symbols are not understood to be artificial and, thus, cannot
be reflectively debugged when they are wrong.  In order to allow these
logical approaches to adapt, I see no alternative but to fundamentally
reinvent all logical approaches to problem solving in reflective terms
that acknowledge a dynamic reality and the static artificiality of
symbols, allowing the potential for debugging meaningful and useful
symbolic constructions.  AI systems must use symbols in full awareness
of their artificial construction as reference to an real unstated
existence, \emph{which can be refined}.

\section{Physical Goals and Failures}

The primary class of goals and failures that can be symbolized is
called the physical goal or failure.  Physical goals and failures
refer to activities in Duration that are the cause for refinement and
initial creation of symbolic perceptions and resources.  These initial
symbolic perceptions and resources are thus physical as well.  The
primary and most fundamental class of causal hypothesis is the
physical causal hypothesis, composed of physical perceptions,
resources, and goals.  All of this initial knowledge stems from the
most fundamental class of goal, the physical goal.

\section{Reflective Classes of Causal Models}

The first-order reflective layer creates causal models from physical
perceptions, resources, goals, and failures.  I've described
previously how goals can cause reflective thinking to create causal
hypotheses.  Another way to state this more succinctly is as follows:
\emph{goals and failures are the cause of causal hypotheses}.  Note
two different meanings of cause in the previous sentence.  In the
latter case, I'm referring to causal models relating physical
perceptions and resources, and in the former case, I'm referring to
the first-order reflective activity that causes the creation of the
physical model.  Thus, the creation of the physical model is a
transition from nothing to existence.

Reflecting over the activities of first-order reflection in Duration
allows my model to represent the transitions caused by first-order
reflective activities.  These transitions are knowledge level changes.
By using this reflective technique, a new class of causal model is
created, categorically different from the physical causal models that
the first-order reflective layer manipulates.  When the activities of
the first-order reflective layer are reflectively symbolized, my model
can then be motivated to learn to accomplish or avoid knowledge level
goals and failures, using knowledge level causal hypotheses.

\section{Probabilistic Causal Models}

Probabilistic models are an advanced and important thinking tool.
Building a probabilistic causal model involves counting symbolic
perceptions, resources, goals, and failures.  For example, let us
consider that two causal hypotheses have been created that reference
the same symbolic cause and the same symbolic perception in the past;
let us say that the only difference between these two hypotheses is
that they reference two different symbolic goals in the future.  This
situation gives my model a reason to further distinguish symbolic
representations for perceptions and resources, introducing more
refined symbols for these perceptions and resources in order to lead
to causal models that are more useful for correctly predicting these
two different symbolic goals.  This would be the appropriate course of
action if we wanted to correctly predict the symbolic goals; however,
there is an opportunity here to build a probabilistic model that does
not refine the symbolization of perceptions or resources.  For
example, both of the two causal hypotheses could be considered
together to compose a probabilistic causal hypothesis.  Using this
probabilistic hypothesis, a future inference could be created that
includes both symbolic goals, each with one half of a potential
existence.  Probabilistic causal hypotheses are useful for predicting
the average number of times that a symbolic event will occur.  Note
that probabilistic causal hypotheses require counting and creating
ratios from the more fundamental non-probabilistic causal hypotheses
from which they are constructed.

