%************************************************
\chapter{Evaluation}
\label{chapter:evaulation}
%************************************************

The focus of this thesis has been a computational implementation of
reflective thinking.  I began in {\mbox{\autoref{part:the_model}}}
with a basic model of actual reflective thinking.  In order to put
this basic model into mathematical terms,
{\mbox{\autoref{part:the_simulation}}} introduced the assumption that
the actual activities in duration can be thought of as an arrangement
of symbols in graph theoretic relationships.  Further, while
maintaining an awareness of the primary modelling focus on actual
reflective thinking, {\mbox{\autoref{part:the_implementation}}} made
the further assumption that the dynamic activity of simulation is a
static logical combinational device.  In this chapter, I evaluate my
model in terms of the following three guiding questions:
\begin{enumerate}
\item What are the goals of the model described in
  {\mbox{\autoref{part:the_model}}} and how well have they been
  accomplished?
\item What are the goals of the mathematical simulation model
  described in {\mbox{\autoref{part:the_simulation}}} and how well
  have they been accomplished?
\item What are the goals of the computational implementation described
  in {\mbox{\autoref{part:the_implementation}}} and how well have they
  been accomplished?
\end{enumerate}

\section{The Model}

The model described in {\mbox{\autoref{part:the_model}}} serves a
number of goals:
\begin{enumerate}
\item To communicate an understanding of the distinction between
  actual continuous dynamic activity as opposed to the static symbolic
  references and models that reflective thinking manipulates, guiding
  thinking about reflective thinking away from ``loopy'' models and
  toward a layered theory of mind that avoids the tautologies inherent
  in such ``loopy'' theories as described by \cite{perlis:2008}.
\item To provide a foundational model that does not assume a
  subjective view of objects, so that this model may lead to models of
  the analogical abstraction of subjective views of objects from
  symbolic goal-oriented plans.
\item To explain how actual logical problem solving may benefit from
  the refinement of symbolic perceptions and action resources in order
  to create better hypothetical models for accomplishing symbolic
  goals.
\item To explain how probabilistic causal models are rationally
  constructed from the more fundamental symbolic perceptions and
  action resources.
\item To explain how neural networks and other objective models of
  ``sub-symbolic'' perception and thinking are at least constructions
  of second-order reflective thinking, more abstract and symbolic than
  the perceptions of the first-order reflective layer that they are
  created to describe.
\item To explain that a model that is grounded in the actual dynamic
  activities that exist can not only represent factual perceptual
  memories of physical activities but also factual perceptual memories
  of thinking activities, such as actual plan failures of the
  reflective thinking layers.  In other words, physical embodiment is
  not necessary in order to model actual reflective thinking.
\end{enumerate}
While I have made every attempt to make
{\mbox{\autoref{part:the_model}}} accessible in non-technical
language, an evaluation of the communicative purposes of this part can
only be evaluated in retrospect.  The evaluation of how well this part
serves as a strong and basic foundation for the subsequent
contributions of this thesis is next evaluated in the terms of those
contributions, respectively.

\section{The Simulation}



\section{Streaming Constant-Time Symbolization}

In {\mbox{\autoref{part:the_simulation}}}, I define a symbolic
represenation to be a subgraph of the dynamic activity in the layers
below the static symbolic reference.  In general, this definition
becomes a subgraph isomorphism problem.  An algorithmic solution to
subgraph isomorphism is known to be an NP-complete problem, requiring
search.  Because my approach requires every activity in the
implementation to take a constant, $O(1)$, time, the symbolic
perception activity must also be composed of constant time components.
The way that this problem is handled in my architecture is by
considering the symbolic perception problem as a
\emph{planning-to-perceive} problem \cite[]{pryorcollins:1995}.  In my
proof-of-concept implementation, I only use graphs that are of a low
enough complexity in order to be bounded by a known constant upper
time boundary.  My implementation only creates new symbols for
those subgraphs that are below the size of four nodes and four edges.
I have hard-coded one two types of symbolic perceptions at the
second-order reflective level that focuses on plans in the focus and
execution registers.

In general, the subgraph isomorphism for specific symbolic perceptions
from the layers below becomes a planning problem for each newly
created symbol.  This allows the planning machine to create plans that
are compiled into parallel resources that can note the perception of
each newly created symbol, based on the reflective copy of the
physical knowledge-base.

