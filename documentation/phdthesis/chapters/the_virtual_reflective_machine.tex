%************************************************
\chapter{The Virtual Reflective Machine}
\label{chapter:the_virtual_reflective_machine}
%************************************************

\newcommand{\FibR}{$\text{Fib}^r$ }
\section{\FibR}

My implementation is based on a virtual machine that allows parallel
and concurrent scheduling of Lisp-like programs.  I refer to this
virtual machine as \FibR, pronouced ``fiber.''  The purpose of \FibR
is to provide a simulation of the actual dynamic qualities of
Duration, the activities in Duration that actually exist.  Of course,
in simulation we are limited to constructing the artificial.  I
clarify that computers cannot generate their own meaning for symbols
in \autoref{section:digital_reflection}; briefly, it is because they
are based on an unchanging combinational device, which limits the
potential meaning of actual computational reflection to a tautology.
The only meaning of the symbols of my simulation are in the eyes of
the beholder.  Under these clear terms, I have nonetheless implemented
my model with the hopes that it may help others to see the utility of
my theory, especially in its simulated form.

\section{Lisp-like Programming Language}

\FibR includes a Lisp-like programming language.

The most primitive component of the \FibR system is an object called a
\emph{fiber}.

\section{Concurrent Memory Allocation Pools}

\FibR works off of a multiple pool memory allocation system that
allows separate pools for each concurrent virtual processor,
eliminating the need for many lock situations that occur with shared
memory pools.

\section{Garbage Collection}



\section{Layered Cognitive Architecture}

On this computational substrate, I have built a layered cognitive
architecture that is inspired by Minsky's description of the bottom
four layers of his Emotion Machine, or Model-6 architecture.  This
includes, a physical world, a reactive mapping of the physical world
to pre-symbolic activities, a first-order reflective thinking layer
that creates symbols, causal models, and plans for accomplishing
physical goals, as well as a second-order reflective thinking layer
that creates symbols, causal models, and plans for accomplishing
first-order thinking goals.  The theory behind this implementation
inductively explains how this implementation can be extended to an
arbitrary number of reflective thinking layers.  While this part of
the thesis is primarily focused on the simulation of an artificial,
modelled representation of this theory, I derive the fundamental basis
of my theory of mind in non-technical English in
\autoref{part:theory_of_mind}.

\section{Block Building Domain}

My architecture exists in three main theoretical parts: the physical
layer, the first-order reflective layer, and the second-order
reflective layer.  In order to explain how my theory allows for
learning at multiple levels, I use a simulation of a physical domain
that is easy to understand.  I use this simulation primarily for
communication of my working theory by demonstrating learning at
multiple reflective levels in response to a single physical failure.

My simulation of the physical block building domain is meant to appear
as similar to the canonical toy problem, \emph{Blocks World}, with one
key exception: my model is meant to have a different interpretation
than the original Blocks World.  The primary point to emphasize here
is that my physical simulation is meant to represent a dynamic
physical world as opposed to the logical and completely static
reference for the Blocks World physical domain.



\section{Reactive Layer}

The physical layer in my theory is implemented by combining the
physical simulation with a reactive layer that maps the physical
simulator perceptual and motor functions to ``sub-symbolic''
activities that are available to first-order reflection.



\section{Leftovers...}

\section{Data Reflection}



\section{The von Neumann Model}

\cite{von_neumann:1945} describes a model of computation that
introduces a concept called \emph{instructions} to the digital
abstraction.  Instructions are a predefined set of arrangements of
symbols that, with other data, determine the future arrangements of
symbols in memory.  Given the von Neumann model, the programming of
each new simulation can be done symbolically rather than by rewiring
the hardware every time.  The von Neumann model is a great technical
achievement that eases the manipulation of simulations, but
fundamentally, the same limitations of digital reflection exist for
the von Neumann model as exist for all computers.  This is because the
von Neumann model still assumes the static unchanging discrete
activity of the combinational device, which causes the transition from
the past to the future.  In the von Neumann model, the combinational
device is more complicated and allows the programmer to more easily
think more abstractly about programs as data.

\section{Instructional Reflection}

The von Neumann model introduces instruction sets that allow programs
to be stored in memory along with other data.

\section{Meaninglessness of the Digital Abstraction}



Because of the inability of a model based on the digital abstraction
to refer to the transition from the past to the future, a
computational model

\section{Leftovers...}

\section{Simulation of a Theory}

Creating a simulation of a theory of mind is useful for a variety of
reasons.  The primary use of simulation is to explore the mechanical
implications of different mechanical assumptions.

\section{Comparing Two Simulations}

Two simulations of two different theories is useful in finding
correlations between these theories.  In order for these correlations
to be meaningful, they must be contained within a more universal
theory that provides a reference to a universal reality.  The idea of
two realities is a contradiction in terms.


\section{Model-6}

My theory does not include Minsky's ``self-reflective'' or
``self-conscious'' layers.  I see objective models of self are
required for what Minsky discusses as self-reflective thinking,
including models of personality recognition and planning.  My model
does not yet have the capability to create or use subjective views of
objects, which I see as necessary not only for self-reflective
thinking, but also Minsky's concept of ``self-conscious'' thinking.
While singly recursive self-reflective statements, like ``Suzy wants
ice-cream'', require learning object and subject relationships, I see
doubly recursive descriptions of personality as necessary for Minsky's
conception of self-conscious thinking, e.g. ``Suzy wants Bob to want
ice-cream.''

