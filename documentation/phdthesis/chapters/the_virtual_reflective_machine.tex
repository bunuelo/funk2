%************************************************
\chapter{The Virtual Reflective Machine}
\label{chapter:the_virtual_reflective_machine}
%************************************************

\newcommand{\FibR}{$\text{Fib}^\text{R}$ }

My implementation is based on a virtual machine that allows parallel
and concurrent scheduling of Lisp-like programs.  I refer to this
virtual machine as \FibR, pronouced ``fiber.''  The purpose of \FibR
is to provide a simulation of the actual dynamic qualities of
Duration, the activities in Duration that actually exist.  I have
previously explained why computers cannot create meaningful symbolic
references to reality, beyond the purely tautological, in
\autoref{section:digital_reflection}.  As is true of all computational
processes, theoretical or otherwise, the meanings of the symbols
generated by my simulation are in the eyes of the beholder.  Under
these terms, I have implemented my model for many reasons.  Primarily,
I will use this model to demonstrate how the mechanics of the theory
can be actually thought about.  Secondarily, I have written the
implementation in order to provide a useful simulation of reflective
thinking for researchers not only in the field of AI but also for
other fields in the more general cognitive sciences that may be
interested in a software simulation of reflective thinking.

\FibR demonstrates multi-layered reflective learning.  I am focusing
in this dissertation on explaining how \FibR demonstrates reflective
learning in two distinct causal classes of knowledge from a single
failure.  First, I will describe how \FibR simulates the activities in
Duration that are actually dynamic and neither separate nor discrete.

\section{Fibers Simulate Activities in Duration}

\FibR introduces an object that represents a parallel process, the
\emph{fiber}.  Fibers are the fundamental element for simulating
concurrent activity in \FibR.  \FibR begins the simulation with only
one fiber that serves a predefined ``boot-up'' function that starts
all of the other concurrent fibers that are necessary for simulating
the mind.  Fibers are the discrete elements that I have used as a
model of the concurrent, actually inseparable, activities in Duration.

My simulation of mind uses hundreds of thousands of fibers in order to
demonstrate two layers of reflective learning.  Fibers are often very
short-lived processes; for example, not execution, but simply
compiling a single Lisp-like expression in \FibR can lead to the
creation and destruction of hundreds of fibers of activity.  Fibers
are useful in programs that could use an extra perspective on a
problem.

\section{Lisp-like Programming Language}

\FibR includes a Lisp-like programming language, which is programmed
by typing statements that are called \emph{expressions}.  If
expression \ref{expression:print_hello} were typed into \FibR, the
symbol ``green'' would be printed to the user's terminal screen.
\begin{equation}
\label{expression:print_hello}
\text{\tt [print `green]}
\end{equation}
The {\tt print} command is a useful debugging tool that can report
status messages to the programmer as the fiber reaches a specific
point in the program.

\section{Sequential and Parallel Programs}

\FibR includes expressions for describing serial and parallel
programs.  For example, the expression
\begin{equation*}
\begin{array}{l}
\text{\tt [prog [print 1]} \\
\text{\tt ~~~~~~[print 2]} \\
\text{\tt ~~~~~~[print 3]]}
\end{array}
\end{equation*}
results in the output trace
\begin{equation*}
\begin{array}{l}
\text{\tt 1} \\
\text{\tt 2} \\
\text{\tt 3.}
\end{array}
\end{equation*}
The command {\tt prog} is a way for expressing a sequence of commands
to be executed in serial order.  \FibR also includes the {\tt parog}
command for executing a list of commands in parallel, waiting for them
all to complete, and then continuing.
\begin{equation*}
\begin{array}{l}
\text{\tt [parog [print 1]} \\
\text{\tt ~~~~~~~[print 2]} \\
\text{\tt ~~~~~~~[print 3]]}
\end{array}
\end{equation*}
When {\tt parog} is used, it is unclear what command will complete
first because they are all running concurrently, in parallel, starting
at slightly different times.  Here is an example output trace from the
{\tt parog} expression:
\begin{equation*}
\begin{array}{l}
\text{\tt 3} \\
\text{\tt 1} \\
\text{\tt 2.}
\end{array}
\end{equation*}
The {\tt parog} expression is one way to easily start a number of
parallel fibers to simultaneously execute a number of different tasks
and wait for these tasks to complete.

\section{Monitoring Simulated Activities in Duration}

\begin{figure}[bth]
  \center
  \includegraphics[width=6cm]{gfx/fibermon_many_fibers}
  \caption[FiberMon monitoring many fibers]{FiberMon monitoring many fibers.}
  \label{figure:fibermon_many_fibers}
\end{figure}


\section{{\tt par-fib}}

\begin{equation*}
\begin{array}{l}
\text{\tt [defunk par-fib [n]} \\
\text{\tt ~~[if [== n 0]} \\
\text{\tt ~~~~~~0} \\
\text{\tt ~~~~[if [== n 1]} \\
\text{\tt ~~~~~~~~1} \\
\text{\tt ~~~~~~[let [[x []]} \\
\text{\tt ~~~~~~~~~~~~[y []]]} \\
\text{\tt ~~~~~~~~[parog [= x [par-fib [- n 2]]]} \\
\text{\tt ~~~~~~~~~~~~~~~[= y [par-fib [- n 1]]]]} \\
\text{\tt ~~~~~~~~[+ x y]]]]]}
\end{array}
\end{equation*}


\section{Symbolic Statements in \FibR}

\section{Three Categories of Symbol}

\FibR programming expressions are combinations of symbols in lists.
It is important to keep all of these symbols straight.  I have so far
introduced three slightly different conceptions of symbols: (1) the
symbols that are reflectively symbolized from the activities of
Duration, (2) the symbols that a programmer types into a computer, and
(3) the simulated symbols that are generated by the simulated
first-order reflective layer of thinking.

\section{Concurrent Memory Allocation Pools}

\FibR works off of a multiple pool memory allocation system that
allows separate pools for each concurrent virtual processor,
eliminating the need for many lock situations that occur with shared
memory pools.

\section{Garbage Collection}



\section{Layered Cognitive Architecture}

On this computational substrate, I have built a layered cognitive
architecture that is inspired by Minsky's description of the bottom
four layers of his Emotion Machine, or Model-6 architecture.  This
includes, a physical world, a reactive mapping of the physical world
to pre-symbolic activities, a first-order reflective thinking layer
that creates symbols, causal models, and plans for accomplishing
physical goals, as well as a second-order reflective thinking layer
that creates symbols, causal models, and plans for accomplishing
first-order thinking goals.  The theory behind this implementation
inductively explains how this implementation can be extended to an
arbitrary number of reflective thinking layers.  While this part of
the thesis is primarily focused on the simulation of an artificial,
modelled representation of this theory, I derive the fundamental basis
of my theory of mind in non-technical English in
\autoref{part:theory_of_mind}.

\section{Block Building Domain}

My architecture exists in three main theoretical parts: the physical
layer, the first-order reflective layer, and the second-order
reflective layer.  In order to explain how my theory allows for
learning at multiple levels, I use a simulation of a physical domain
that is easy to understand.  I use this simulation primarily for
communication of my working theory by demonstrating learning at
multiple reflective levels in response to a single physical failure.

My simulation of the physical block building domain is meant to appear
as similar to the canonical toy problem, \emph{Blocks World}, with one
key exception: my model is meant to have a different interpretation
than the original Blocks World.  The primary point to emphasize here
is that my physical simulation is meant to represent a dynamic
physical world as opposed to the logical and completely static
reference for the Blocks World physical domain.



\section{Reactive Layer}

The physical layer in my theory is implemented by combining the
physical simulation with a reactive layer that maps the physical
simulator perceptual and motor functions to ``sub-symbolic''
activities that are available to first-order reflection.



\section{Leftovers...}

\section{Data Reflection}



\section{The von Neumann Model}

\cite{von_neumann:1945} describes a model of computation that
introduces a concept called \emph{instructions} to the digital
abstraction.  Instructions are a predefined set of arrangements of
symbols that, with other data, determine the future arrangements of
symbols in memory.  Given the von Neumann model, the programming of
each new simulation can be done symbolically rather than by rewiring
the hardware every time.  The von Neumann model is a great technical
achievement that eases the manipulation of simulations, but
fundamentally, the same limitations of digital reflection exist for
the von Neumann model as exist for all computers.  This is because the
von Neumann model still assumes the static unchanging discrete
activity of the combinational device, which causes the transition from
the past to the future.  In the von Neumann model, the combinational
device is more complicated and allows the programmer to more easily
think more abstractly about programs as data.

\section{Instructional Reflection}

The von Neumann model introduces instruction sets that allow programs
to be stored in memory along with other data.

\section{Meaninglessness of the Digital Abstraction}



Because of the inability of a model based on the digital abstraction
to refer to the transition from the past to the future, a
computational model

\section{Leftovers...}

\section{Simulation of a Theory}

Creating a simulation of a theory of mind is useful for a variety of
reasons.  The primary use of simulation is to explore the mechanical
implications of different mechanical assumptions.

\section{Comparing Two Simulations}

Two simulations of two different theories is useful in finding
correlations between these theories.  In order for these correlations
to be meaningful, they must be contained within a more universal
theory that provides a reference to a universal reality.  The idea of
two realities is a contradiction in terms.


\section{Model-6}

My theory does not include Minsky's ``self-reflective'' or
``self-conscious'' layers.  I see objective models of self are
required for what Minsky discusses as self-reflective thinking,
including models of personality recognition and planning.  My model
does not yet have the capability to create or use subjective views of
objects, which I see as necessary not only for self-reflective
thinking, but also Minsky's concept of ``self-conscious'' thinking.
While singly recursive self-reflective statements, like ``Suzy wants
ice-cream'', require learning object and subject relationships, I see
doubly recursive descriptions of personality as necessary for Minsky's
conception of self-conscious thinking, e.g. ``Suzy wants Bob to want
ice-cream.''

