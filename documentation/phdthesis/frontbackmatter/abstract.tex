%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}

A system built on a layered reflective cognitive architecture, such as
that advocated by Minsky, presents many novel and difficult
software-engineering problems.  Some of these problems can be
ameliorated by erecting the system on a substrate that implicitly
supports tracing of results and behavior of the system to the data and
through the procedures that produced those results and that behavior.
Good traces make the system accountable: it enables the analysis of
success and failure, and thus enhances the ability to learn from
mistakes.

I have constructed just such a substrate.  It provides for general
parallelism and concurrency, while supporting the automatic collection
of audit trails for all processes, including the processes that
analyze audit trails.  My system natively supports a Lisp-like
language.  In such a language, as in machine language, a program is
data that can be easily manipulated by a program.  This makes it
easier for a user (or an automatic procedure) to read, edit, and write
programs, as they are debugged.

Building on the work of Pushpinder Singh I build and demonstrate an
example cognitive architecture simulation of life in a rigidbody
physical environment.  In my demonstration multiple agents can learn
from experience of success or failure, or by being explicitly taught
by other agents (including the user).  In my demonstration I show how
procedurally traced memory can be used to assign credit to those
deliberative processes that are responsible for the failure,
facilitating learning how to better plan for these types of problems
in the future.

\endgroup

\vfill



%Building a machine that demonstrates the general intelligence required
%for commonsense reasoning is a longstanding goal of the field of
%artificial intelligence.  There have been many approaches to building
%a machine that demonstrates general intelligence, some are based on
%logical representations, others are based on large collections of
%statistical knowledge, while still others approach the problem by
%learning everything from scratch from the physical world.  We see the
%problem as requiring a combination of many different types of
%representations and reasoning processes.
%
%We worked with Push Singh from 1999 to 2006 on the first version of
%the Emotion Machine architecture, EM1.  During that period, we
%discussed that one weakness in the EM1 system is its reliance on
%tracing only the declarative prolog statements, among other necessary
%but untraced procedural code.  Although EM1 contained a large amount
%of procedural knowledge, none of the effects of this procedural
%knowledge could be debugged reflectively.  Toward solving this
%problem, we have based our approach on a memory layer that can trace
%the provenance of select memory events.
%
%Because the Emotion Machine theory of mind requires a variety of many
%reasoning processes to be controlled, we have built an operating
%system on top of this traceable memory layer.
%
%Further, the Emotion Machine is organized into layers of different
%representations, so we have built a lisp-like language on top this
%operating system.  The benefit of having a lisp-like language is the
%language's ability to efficiently represent and simulate new
%programming languages.
%
%Within our lisp-like language we have written an implementation of a
%layered reflective cognitive architecture, inspired by EM1.
%
%Finally, we demonstrate our cognitive architecture in a rigid-body
%physical environment, where multiple agents demonstrate learning from
%both being told solutions to problems as well as learning from the
%environment in which situations these solutions succeed or fail.  We
%show how our procedurally traced memory can be used to assign credit
%to those deliberative processes that are responsible for the failure,
%facilitating learning how to better plan for these types of problems
%in the future.






%Systems that demonstrate social and physical world learning have had
%not been successful at tracing cause and effect reflectively. Lack of
%reflective debugging of procedural knowledge has continued to be the
%reason that many AI systems from qualitative reasoning, to ontology
%based common sense approaches to logical AI approaches have been
%brittle.  This thesis demonstrates a layered architecture for
%reflective intelligence.  Based on the XXXX human cognitive model, the
%reflective intelligence includes 6 layers reactive, learned reactive,
%deliberative, reflective, self-reflective, and self-conscious
%thinking. The model is designed to drive system learning with a
%imprimer attachment theory, a theory of how children inherit goals
%from parents.
%
%The theory is demonstrated in a simulated physical space.  The
%demonstraton shows multiple autonomous knowledgeable agents learning
%both from being told solutions to problems as well as learning from
%running their own exploration experiments to reflect on solutions that
%succeed or fail.
%
%This thesis puts forward a first trace based demonstration of
%reflection for debugging layered and heterogeneous procedural
%knowledge systems.


%There have been two directions of research with the goal of building a
%machine that explains intelligent human behavior.  The first approach
%is to build a baby-machine that learns from scratch to accomplish
%goals through interactions with its environment.  The second approach
%is to give the machine an abundance of knowledge that represents
%correct behavior.
%
%Each of these solutions has benefits and drawbacks.  The baby-machine
%approach is good for dealing with novel problems, but these problems
%are necessarily simple because complex problems require a lot of
%background knowledge.  The data abundance approach deals well with
%complicated problems requiring a lot of background knowledge, but
%fails to adapt to changing environments, for which the algorithm has
%not already been trained.
%
%We are working on an algorithm that benefits from both of these
%approaches by learning from cultural language knowledge, while
%reflectively monitoring and recognizing the failures of this knowledge
%when it is used in a goal-oriented domain.
%
%Toward this end we have developed a reflective programming language
%allowing us the ability to monitor the execution and interactions
%between large numbers of complicated lisp-like processes.  Further, we
%have developed a cognitive architecture within our language that
%provides structures for layering reflective processes, resulting in a
%hierarchy of control algorithms that respond to failures in the layers
%below.
%
%Finally, we present an example of our cognitive architecture learning
%in the context of a social commonsense reasoning domain with parents
%that teach children as they attempt to accomplish cooking tasks in a
%kitchen.

