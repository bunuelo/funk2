%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}

Building a machine that demonstrates the general intelligence required
for commonsense reasoning is a longstanding goal of the field of
artificial intelligence.  There have been many approaches to building
a machine that demonstrates general intelligence, some are based on
logical representations, others are based on large collections of
statistical knowledge, while still others approach the problem by
learning everything from scratch from the physical world.  We see the
problem as requiring a combination of many different types of
representations and reasoning processes.

We worked with Push Singh from 1999 to 2006 on the first version of
the Emotion Machine architecture, EM1.  During that period, we
discussed that one weakness in the EM1 system is its reliance on
tracing only the declarative prolog statements, among other necessary
but untraced procedural code.  Although EM1 contained a large amount
of procedural knowledge, none of the effects of this procedural
knowledge could be debugged reflectively.  Toward solving this
problem, we have based our approach on a memory layer that can trace
the provenance of select memory events.

Because the Emotion Machine theory of mind requires a variety of many
reasoning processes to be controlled, we have built an operating
system on top of this traceable memory layer.

Further, the Emotion Machine is organized into layers of different
representations, so we have built a lisp-like language on top this
operating system.  The benefit of having a lisp-like language is the
language's ability to efficiently represent and simulate new
programming languages.

Within our lisp-like language we have written an implementation of a
layered reflective cognitive architecture, inspired by EM1.

Finally, we demonstrate our cognitive architecture in a rigid-body
physical environment, where multiple agents demonstrate learning from
both being told solutions to problems as well as learning from the
environment in which situations these solutions succeed or fail.  We
show how our procedurally traced memory can be used to assign credit
to those deliberative processes that are responsible for the failure,
facilitating learning how to better plan for these types of problems
in the future.

\endgroup

\vfill


%Systems that demonstrate social and physical world learning have had
%not been successful at tracing cause and effect reflectively. Lack of
%reflective debugging of procedural knowledge has continued to be the
%reason that many AI systems from qualitative reasoning, to ontology
%based common sense approaches to logical AI approaches have been
%brittle.  This thesis demonstrates a layered architecture for
%reflective intelligence.  Based on the XXXX human cognitive model, the
%reflective intelligence includes 6 layers reactive, learned reactive,
%deliberative, reflective, self-reflective, and self-conscious
%thinking. The model is designed to drive system learning with a
%imprimer attachment theory, a theory of how children inherit goals
%from parents.
%
%The theory is demonstrated in a simulated physical space.  The
%demonstraton shows multiple autonomous knowledgeable agents learning
%both from being told solutions to problems as well as learning from
%running their own exploration experiments to reflect on solutions that
%succeed or fail.
%
%This thesis puts forward a first trace based demonstration of
%reflection for debugging layered and heterogeneous procedural
%knowledge systems.


%There have been two directions of research with the goal of building a
%machine that explains intelligent human behavior.  The first approach
%is to build a baby-machine that learns from scratch to accomplish
%goals through interactions with its environment.  The second approach
%is to give the machine an abundance of knowledge that represents
%correct behavior.
%
%Each of these solutions has benefits and drawbacks.  The baby-machine
%approach is good for dealing with novel problems, but these problems
%are necessarily simple because complex problems require a lot of
%background knowledge.  The data abundance approach deals well with
%complicated problems requiring a lot of background knowledge, but
%fails to adapt to changing environments, for which the algorithm has
%not already been trained.
%
%We are working on an algorithm that benefits from both of these
%approaches by learning from cultural language knowledge, while
%reflectively monitoring and recognizing the failures of this knowledge
%when it is used in a goal-oriented domain.
%
%Toward this end we have developed a reflective programming language
%allowing us the ability to monitor the execution and interactions
%between large numbers of complicated lisp-like processes.  Further, we
%have developed a cognitive architecture within our language that
%provides structures for layering reflective processes, resulting in a
%hierarchy of control algorithms that respond to failures in the layers
%below.
%
%Finally, we present an example of our cognitive architecture learning
%in the context of a social commonsense reasoning domain with parents
%that teach children as they attempt to accomplish cooking tasks in a
%kitchen.

